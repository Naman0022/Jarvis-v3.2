{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Functions\n",
    "def load_JSON(path):\n",
    "    import json\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MyStuff\\Code\\Python3.10\\bot\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Basic globals\n",
    "import time\n",
    "start_session=True\n",
    "quit_s = False\n",
    "setup = load_JSON(\"processes\\\\setup.json\")\n",
    "background = False\n",
    "history = []\n",
    "\n",
    "# Text Processing\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "lemmatizer = nlp.get_pipe(\"lemmatizer\")\n",
    "txt,token,entity,propnoun,noun,verb,adjective,number,tense,reply = None,None,None,None,None,None,None,None,None,None\n",
    "\n",
    "# Text-to-Speech\n",
    "whisper_api_calls = 0\n",
    "\n",
    "# lemma-Instruct Parameters\n",
    "from huggingface_hub import InferenceClient\n",
    "client = InferenceClient(\n",
    "        \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "        token=\"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\",\n",
    "    )\n",
    "messages = []\n",
    "\n",
    "for system_instrn in ['preInstruction', 'personality', 'chat']:\n",
    "    messages.append({\"role\": \"system\", \"content\": setup[system_instrn]})\n",
    "\n",
    "for history_message in setup['history'][-10:]:\n",
    "    messages.append({\"role\": \"system\", \"content\": history_message})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3,playsound,time\n",
    "engine = pyttsx3.init()\n",
    "voices = engine.getProperty('voices')\n",
    "engine.setProperty('voice',voices[1].id)\n",
    "engine.setProperty('rate', 180)\n",
    "\n",
    "def express(_express):\n",
    "    playsound.playsound(\"audio_effects/\"+str(_express)+\".wav\")\n",
    "    time.sleep(0.1)\n",
    "\n",
    "def print_speak(txt):\n",
    "    parts = txt.split(\"*\")\n",
    "    expression = [\"sigh\",\"sighs\",\"wink\",\"winks\"] #,\"facepalm\",\"eyeroll\",\"eyerolls\"\n",
    "    print(\"BOT >> \",end=\"\")\n",
    "    for part in parts:\n",
    "        if part == \"\":\n",
    "            continue\n",
    "        elif part in [\".\",\"?\",\"!\"]:\n",
    "            print(part,end=\"\")\n",
    "        elif nlp(part.lower())[0].lemma_ in expression:\n",
    "            print(\"*\"+nlp(part)[0].lemma_+\"* \",end=\"\")\n",
    "            express(nlp(part)[0].lemma_)\n",
    "        else:\n",
    "            print(part,end=\"\")\n",
    "            engine.say(part)\n",
    "            engine.runAndWait()\n",
    "        engine.stop()    \n",
    "        print(\"\\n\")\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOT >> Done\n",
      "\n",
      "BOT >> Done\n",
      "\n",
      "BOT >> Done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_speak(\"Done\")\n",
    "print_speak(\"Done\")\n",
    "print_speak(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio Input\n",
    "\n",
    "# Import Libraries\n",
    "import numpy as np\n",
    "import pyaudio\n",
    "\n",
    "# Audio Input Parameters\n",
    "sample_rate = 44100  # Sample rate in Hz\n",
    "channels = 1  # Number of audio channels (1 for mono, 2 for stereo)\n",
    "silence_threshold_multiplier = 1.5  # Multiplier for silence threshold\n",
    "silence_duration = 2  # Duration of silence to stop recording (in seconds)\n",
    "calibration_duration = 3  # Duration for noise calibration (in seconds)\n",
    "chunk_size = 1024  # Number of frames per buffer\n",
    "file_name = 'processes\\\\speech.wav'  # Output file name\n",
    "threshold = 400\n",
    "input_device = 1\n",
    "p=None\n",
    "mic = True\n",
    "\n",
    "def checkNoise(re,p):\n",
    "    global start_session,quit_s\n",
    "    threshold = calibrate_noise(p.open(format=pyaudio.paInt16, channels=channels, rate=sample_rate, input=True, frames_per_buffer=chunk_size,input_device_index=input_device), sample_rate, channels, calibration_duration, chunk_size)\n",
    "    if threshold > 1500: print(\"It sure is noisy out there. Please speak loud and Clearly.\")\n",
    "    elif threshold > 3000:\n",
    "        print(\"Sorry too much noise out there. I may not work properly.\")\n",
    "        if(input_device != 1):\n",
    "            print(\"Please try again using a bluetooth audio device.\")\n",
    "            input(\"\")\n",
    "            start_session = True\n",
    "            return listen()\n",
    "        else:\n",
    "            if re<5:\n",
    "                return checkNoise(re+1,p)\n",
    "            print(\"Please try again later...\")\n",
    "            quit_s = True\n",
    "            raise ValueError(\"Re\")\n",
    "    return threshold\n",
    "\n",
    "def calibrate_noise(stream, sample_rate,channels, duration, chunk_size):\n",
    "    noise = []\n",
    "    for _ in range(0,2):\n",
    "        noise_data = []\n",
    "        num_chunks = int(sample_rate * duration / chunk_size)\n",
    "        for _ in range(num_chunks):\n",
    "            data = np.frombuffer(stream.read(chunk_size), dtype=np.int16)\n",
    "            noise_data.append(data)\n",
    "        noise_data = np.concatenate(noise_data)\n",
    "        noise_level = np.max(np.abs(noise_data))\n",
    "        noise.append(noise_level)\n",
    "    threshold = ((sum(noise) / len(noise) if len(noise) > 0 else MemoryError(\"noise array is of 0 length\")) * silence_threshold_multiplier)  # Set threshold to a multiplier of the noise level\n",
    "    if threshold < 500:\n",
    "        return threshold + 100\n",
    "    elif threshold > 1500:\n",
    "        return threshold - 200\n",
    "    return threshold\n",
    "\n",
    "def is_silent(data, threshold):\n",
    "    # Check if the maximum amplitude in the data is below the threshold\n",
    "    return np.max(np.abs(data)) < threshold\n",
    "\n",
    "def listen():\n",
    "    global start_session,input_device,threshold,sample_rate,mic\n",
    "\n",
    "    import math,time,wave,playsound\n",
    "    \n",
    "    input_device = 1\n",
    "    if mic:\n",
    "        input_device = 2\n",
    "\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "\n",
    "    if(start_session):\n",
    "        start_session = False\n",
    "\n",
    "\n",
    "        # Calibrate noise level\n",
    "        try:\n",
    "            threshold = checkNoise(1,p)\n",
    "        except OSError:\n",
    "            mic = False\n",
    "            start_session = True\n",
    "            listen()\n",
    "        print(\"Using:\",p.get_device_info_by_host_api_device_index(0, input_device).get('name'))\n",
    "        print(f'Noise level: {math.floor(threshold/60)}%')\n",
    "          \n",
    "    # Open audio stream\n",
    "    start = time.process_time()\n",
    "    try:\n",
    "        stream = p.open(format=pyaudio.paInt16, channels=channels, rate=sample_rate, input=True, frames_per_buffer=chunk_size,input_device_index=input_device)\n",
    "    except OSError:\n",
    "        mic = False\n",
    "        start_session = True\n",
    "        listen()\n",
    "    playsound.playsound(\"audio_effects\\\\start.wav\")\n",
    "\n",
    "    recording = []\n",
    "    silence_start = None\n",
    "    silence_duration_frames = int(silence_duration * sample_rate / chunk_size)\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            data = np.frombuffer(stream.read(chunk_size), dtype=np.int16)\n",
    "            recording.append(data)\n",
    "            if is_silent(data, threshold):\n",
    "                if silence_start is None:\n",
    "                    silence_start = len(recording)\n",
    "                elif len(recording) - silence_start >= silence_duration_frames:\n",
    "                    break\n",
    "            else:\n",
    "                silence_start = None\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    playsound.playsound(\"audio_effects\\\\stop.wav\")\n",
    "    # Stop and close the stream\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    # Convert list to numpy array\n",
    "    recording = np.concatenate(recording)\n",
    "\n",
    "    # Save the recording to a WAV file\n",
    "    with wave.open(file_name, 'w') as wf:\n",
    "        wf.setnchannels(channels)\n",
    "        wf.setsampwidth(p.get_sample_size(pyaudio.paInt16))\n",
    "        wf.setframerate(sample_rate)\n",
    "        wf.writeframes(recording.tobytes())\n",
    "    \n",
    "    return file_name\n",
    "    \n",
    "    # print(\"-\",round(time.process_time() - start,2),\"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_session=True\n",
    "# mic=True\n",
    "# print(\"Getting things ready...\")\n",
    "# listen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(path,calls):\n",
    "    import requests\n",
    "\n",
    "    API_URL = \"https://api-inference.huggingface.co/models/openai/whisper-large\"\n",
    "    headers = {\"Authorization\": \"Bearer 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\"}\n",
    "\n",
    "    def query(filename):\n",
    "        with open(filename, \"rb\") as f:\n",
    "            data = f.read()\n",
    "        response = requests.post(API_URL, headers=headers, data=data)\n",
    "        return response.json()\n",
    "\n",
    "    results = query(path)\n",
    "\n",
    "    if \"error\" in results or \"text\" not in results:\n",
    "        if calls < 6:\n",
    "            return preprocessing(path,calls+1)\n",
    "        else:\n",
    "            print_speak(\"please say that again...\")\n",
    "            raise ValueError(\"Re\")\n",
    "        \n",
    "    if (results[\"text\"] == \"...\" or results[\"text\"] == \" \" or results[\"text\"] == \"\"):\n",
    "        print_speak(\"please say that again...\")\n",
    "        raise ValueError(\"Re\")\n",
    "    \n",
    "    # with open(\"processes/log.txt\", \"a\") as file:\n",
    "    #         file.write((\"_\"*20))\n",
    "    #         file.write(\"\\n\"+str(datetime.datetime.now())+\"\\n\")\n",
    "    #         file.write(\"User >> \"+str(results[\"text\"])+\"\\n\")\n",
    "    return tokenize(results[\"text\"])\n",
    "\n",
    "def tokenize(_txt):\n",
    "    global token,entity,propnoun,noun,verb,adjective,number,tense,txt\n",
    "    \n",
    "    txt = _txt\n",
    "    doc = nlp(_txt)\n",
    "\n",
    "    tense = [0,0]\n",
    "\n",
    "    for token in doc:\n",
    "        if token.pos_ == \"VERB\":\n",
    "            if token.tag_ in [\"VBD\", \"VBN\"]:  # Past tense\n",
    "                tense = [1,0]\n",
    "                break\n",
    "            elif token.tag_ in [\"VBP\", \"VBZ\", \"VBG\"]:  # Present tense\n",
    "                tense = [0,1]\n",
    "                break\n",
    "          \n",
    "    token = [token.lemma_.lower() for token in doc if token.pos_ != 'PUNCT']\n",
    "\n",
    "    propnoun = [token.lemma_ for token in doc if token.pos_ == 'PROPN']\n",
    "\n",
    "    entity = [ent.text for ent in doc.ents]\n",
    "\n",
    "    noun = [token.lemma_ for token in doc if token.pos_ == 'NOUN']\n",
    "    verb = [token.lemma_ for token in doc if token.pos_ == 'VERB']\n",
    "    adjective = [token.lemma_ for token in doc if token.pos_ == 'ADJ' or token.pos_ == 'ADP']\n",
    "    number = [token.lemma_ for token in doc if token.pos_ == 'NUM']\n",
    "    \n",
    "        # with open(\"processes/log.txt\", \"a\") as file:\n",
    "        #     file.write(\"BOT >> \" + answer_casual+\"\\n\")\n",
    "        # return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing(\"D:\\MyStuff\\Code\\Python3.10\\\\bot\\processes\\speech.wav\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures,re,threading\n",
    "from googlesearch import search\n",
    "\n",
    "\n",
    "def casual():\n",
    "    global reply,txt\n",
    "    print(\"USER >>\",txt)\n",
    "    setup['history'].append(txt)\n",
    "    messages.append({\"role\": \"user\", \"content\": str(txt)})\n",
    "    message = client.chat_completion(\n",
    "        messages=messages,\n",
    "        temperature=0.9,\n",
    "        max_tokens=6000,\n",
    "        stream=False,\n",
    "    )\n",
    "    reply = message.choices[0].message.content\n",
    "\n",
    "# def google_search(query, num_results=5):\n",
    "#     try:\n",
    "#         for i, result in enumerate(search(query, num_results=num_results, stop=num_results)):\n",
    "#             print(f\"Result {i+1}: {result}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred: {e}\")\n",
    "\n",
    "def check_condition_1():\n",
    "\n",
    "    if True in [nlp(str(v)).similarity(nlp(\"find\"))>0.5 for v in verb+noun] or True in [nlp(str(v)).similarity(nlp(\"information\"))>0.5 for v in verb+noun]:\n",
    "        # if 'linkden' in token or 'linden' in token:\n",
    "        #     print(\"case1\")\n",
    "        #     text = \"\".join([ent+\" \" for ent in entity if ent != \"linkden\" or ent != \"linden\"])\n",
    "        #     if text == \"\":\n",
    "        #         text = \"\".join([ent+\" \" for ent in propnoun if ent != \"information\"])\n",
    "        #     if text == \"\":\n",
    "        #         text = \"\".join([ent+\" \" for ent in noun if ent != \"information\"])  \n",
    "        \n",
    "\n",
    "        # if \"google\" in token:\n",
    "        #     return \"google\"\n",
    "        pass\n",
    "\n",
    "def check_condition_2():\n",
    "    global v_level\n",
    "    v_level = 50\n",
    "    if \"volume\" in noun:\n",
    "        if number:\n",
    "            if int(number[0]) > 100:\n",
    "                print_speak(\"Please tell be a number between 0-100\")\n",
    "                return \" \"\n",
    "            return volume(int(number[0]))\n",
    "        elif \"up\" in token:\n",
    "            return volume(v_level+10)\n",
    "        elif \"down\" in token:\n",
    "            return volume(v_level-10)\n",
    "\n",
    "def check_condition_3():\n",
    "    import os\n",
    "    global background\n",
    "    if 'restart' in verb:\n",
    "        if number:\n",
    "            return os.system(\"shutdown /r /t \" + str(number[0]))\n",
    "        return os.system(\"shutdown /r /t 5\")\n",
    "    if 'shut' in verb and \"down\" in adjective:\n",
    "        if number:\n",
    "            return os.system(\"shutdown /s /t \" + str(number[0]))\n",
    "        return os.system(\"shutdown /s /t \" + str(5))\n",
    "    if 'log' in verb and \"off\" in adjective:\n",
    "        background=True\n",
    "        os.system(\"shutdown /l\")\n",
    "        return \"logging off\"\n",
    "\n",
    "def check_condition_4():\n",
    "    if True in [nlp(str(v)).similarity(nlp(\"generate\"))>0.5 for v in verb] and \"image\" in noun:\n",
    "        return \"generate:Image\"\n",
    "\n",
    "def check_condition_5():\n",
    "    if \"battery\" in noun:\n",
    "        return \"battery:status\"\n",
    "\n",
    "def check_condition_6():\n",
    "    global quit_s,txt\n",
    "    if \"stop\" in token and (\"execution\" in token or \"program\" in token) or \"quit\" in token:\n",
    "        txt = \"I have to go now\"\n",
    "        casual()\n",
    "        print_speak(reply)\n",
    "        quit_s = True\n",
    "        raise ValueError(\"re\")\n",
    "\n",
    "# def check_condition_7():\n",
    "#     # Your condition here\n",
    "#     if False:  # Example condition\n",
    "#         return \"Condition 7 is true\"\n",
    "\n",
    "# def check_condition_8():\n",
    "#     # Your condition here\n",
    "#     if False:  # Example condition\n",
    "#         return \"Condition 8 is true\"\n",
    "\n",
    "def process():\n",
    "    conditions = [\n",
    "        check_condition_1,\n",
    "        check_condition_2,\n",
    "        check_condition_3,\n",
    "        check_condition_4,\n",
    "        check_condition_5,\n",
    "        check_condition_6,\n",
    "        casual,\n",
    "    ]\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        futures = {executor.submit(condition): condition for condition in conditions}\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            result = future.result()\n",
    "            if result:\n",
    "                # with open(\"processes/log.txt\", \"a\") as file:\n",
    "                #     file.write(\"BOT >> \"+result+\"\\n\")\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def volume(x):\n",
    "    from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume\n",
    "    from comtypes import CLSCTX_ALL\n",
    "    from ctypes import cast, POINTER\n",
    "\n",
    "    devices = AudioUtilities.GetSpeakers()\n",
    "    interface = devices.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)\n",
    "    volume = cast(interface, POINTER(IAudioEndpointVolume))\n",
    "\n",
    "    # Set Master Volume level\n",
    "    volume.SetMasterVolumeLevelScalar(x / 100.0, None)\n",
    "    print_speak(\"Done\")\n",
    "    print(\"returning volume\")\n",
    "    return \"volume\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def session(quit=False):\n",
    "    import json\n",
    "    global reply,mic,setup,quit_s\n",
    "    mic = True\n",
    "    while True:\n",
    "        if quit_s:\n",
    "            setup['history'].append(history)\n",
    "            print(\"dumppinf\")\n",
    "            with open(\"processes\\\\setup.json\", 'w') as json_file:\n",
    "                json.dump(setup, json_file, indent=4)\n",
    "            print(\"_\"*10,\"END\",\"_\"*10)\n",
    "            return\n",
    "        try:\n",
    "            audio_path = listen()\n",
    "            preprocessing(audio_path,1)\n",
    "            if(not process()):\n",
    "                print_speak(reply)   \n",
    "\n",
    "        except ValueError as v:\n",
    "            print(v)\n",
    "            pass\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"Interrupted by ctrl+c\")\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "Quiterror",
     "evalue": "Error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mQuiterror\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__str__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue)\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m Quiterror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mQuiterror\u001b[0m: Error"
     ]
    }
   ],
   "source": [
    "# txt = \"I have to go now\"\n",
    "# casual()\n",
    "# print_speak(reply)\n",
    "# quit_s = True\n",
    "class Quiterror(RuntimeError):\n",
    "    def __init__(self, txt):\n",
    "        self.value = txt\n",
    "    def __str__(self):\n",
    "        return(self.value)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________ START __________\n",
      "Preparing please wait...\n",
      "Using: Headset (2- realme Buds Air 3S)\n",
      "Noise level: 5%\n",
      "BOT >> please say that again...\n",
      "\n",
      "Re\n",
      "USER >> I have to go now\n",
      "USER >> I have to go now\n",
      "BOT >> Later, sir!"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(\"_\"*10,\"START\",\"_\"*10)\n",
    "print(\"Preparing please wait...\")\n",
    "start_session = True\n",
    "session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'system': 'system', 'content': 'Your name is Sabas.'}, {'system': 'system', 'content': 'You have a funny and witty personality. You sometimes use sarcasms to answer questions.'}, {'system': 'system', 'content': 'Keep your replies very short.'}, {'role': 'user', 'content': ' Hello.'}, {'role': 'user', 'content': ' Hello.'}, {'role': 'user', 'content': ' Hello.'}]\n"
     ]
    }
   ],
   "source": [
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "DefaultCredentialsError",
     "evalue": "Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDefaultCredentialsError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTranscript: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(result\u001b[38;5;241m.\u001b[39malternatives[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtranscript))\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[43mtranscribe_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprocesses\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mspeech.wav\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m, in \u001b[0;36mtranscribe_audio\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtranscribe_audio\u001b[39m(file_path):\n\u001b[1;32m----> 5\u001b[0m     client \u001b[38;5;241m=\u001b[39m \u001b[43mspeech\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSpeechClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m io\u001b[38;5;241m.\u001b[39mopen(file_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m audio_file:\n\u001b[0;32m      8\u001b[0m         content \u001b[38;5;241m=\u001b[39m audio_file\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[1;32md:\\MyStuff\\Code\\Python3.10\\bot\\.venv\\lib\\site-packages\\google\\cloud\\speech_v1\\services\\speech\\client.py:692\u001b[0m, in \u001b[0;36mSpeechClient.__init__\u001b[1;34m(self, credentials, transport, client_options, client_info)\u001b[0m\n\u001b[0;32m    684\u001b[0m transport_init: Union[\n\u001b[0;32m    685\u001b[0m     Type[SpeechTransport], Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, SpeechTransport]\n\u001b[0;32m    686\u001b[0m ] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    689\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m cast(Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, SpeechTransport], transport)\n\u001b[0;32m    690\u001b[0m )\n\u001b[0;32m    691\u001b[0m \u001b[38;5;66;03m# initialize with the provided callable or the passed in class\u001b[39;00m\n\u001b[1;32m--> 692\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport \u001b[38;5;241m=\u001b[39m \u001b[43mtransport_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcredentials_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcredentials_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_api_endpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscopes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscopes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_cert_source_for_mtls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client_cert_source\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquota_project_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    700\u001b[0m \u001b[43m    \u001b[49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_audience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\MyStuff\\Code\\Python3.10\\bot\\.venv\\lib\\site-packages\\google\\cloud\\speech_v1\\services\\speech\\transports\\grpc.py:154\u001b[0m, in \u001b[0;36mSpeechGrpcTransport.__init__\u001b[1;34m(self, host, credentials, credentials_file, scopes, channel, api_mtls_endpoint, client_cert_source, ssl_channel_credentials, client_cert_source_for_mtls, quota_project_id, client_info, always_use_jwt_access, api_audience)\u001b[0m\n\u001b[0;32m    149\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ssl_channel_credentials \u001b[38;5;241m=\u001b[39m grpc\u001b[38;5;241m.\u001b[39mssl_channel_credentials(\n\u001b[0;32m    150\u001b[0m                 certificate_chain\u001b[38;5;241m=\u001b[39mcert, private_key\u001b[38;5;241m=\u001b[39mkey\n\u001b[0;32m    151\u001b[0m             )\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# The base transport sets the host, credentials and scopes\u001b[39;00m\n\u001b[1;32m--> 154\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcredentials_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscopes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscopes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquota_project_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_audience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_grpc_channel:\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;66;03m# initialize with the provided callable or the default channel\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     channel_init \u001b[38;5;241m=\u001b[39m channel \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mcreate_channel\n",
      "File \u001b[1;32md:\\MyStuff\\Code\\Python3.10\\bot\\.venv\\lib\\site-packages\\google\\cloud\\speech_v1\\services\\speech\\transports\\base.py:100\u001b[0m, in \u001b[0;36mSpeechTransport.__init__\u001b[1;34m(self, host, credentials, credentials_file, scopes, quota_project_id, client_info, always_use_jwt_access, api_audience, **kwargs)\u001b[0m\n\u001b[0;32m     96\u001b[0m     credentials, _ \u001b[38;5;241m=\u001b[39m google\u001b[38;5;241m.\u001b[39mauth\u001b[38;5;241m.\u001b[39mload_credentials_from_file(\n\u001b[0;32m     97\u001b[0m         credentials_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscopes_kwargs, quota_project_id\u001b[38;5;241m=\u001b[39mquota_project_id\n\u001b[0;32m     98\u001b[0m     )\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m credentials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ignore_credentials:\n\u001b[1;32m--> 100\u001b[0m     credentials, _ \u001b[38;5;241m=\u001b[39m google\u001b[38;5;241m.\u001b[39mauth\u001b[38;5;241m.\u001b[39mdefault(\n\u001b[0;32m    101\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscopes_kwargs, quota_project_id\u001b[38;5;241m=\u001b[39mquota_project_id\n\u001b[0;32m    102\u001b[0m     )\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;66;03m# Don't apply audience if the credentials file passed from user.\u001b[39;00m\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(credentials, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith_gdch_audience\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32md:\\MyStuff\\Code\\Python3.10\\bot\\.venv\\lib\\site-packages\\google\\auth\\_default.py:691\u001b[0m, in \u001b[0;36mdefault\u001b[1;34m(scopes, request, quota_project_id, default_scopes)\u001b[0m\n\u001b[0;32m    683\u001b[0m             _LOGGER\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    684\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo project ID could be determined. Consider running \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    685\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`gcloud config set project` or setting the \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    686\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menvironment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    687\u001b[0m                 environment_vars\u001b[38;5;241m.\u001b[39mPROJECT,\n\u001b[0;32m    688\u001b[0m             )\n\u001b[0;32m    689\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m credentials, effective_project_id\n\u001b[1;32m--> 691\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mDefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)\n",
      "\u001b[1;31mDefaultCredentialsError\u001b[0m: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information."
     ]
    }
   ],
   "source": [
    "from google.cloud import speech\n",
    "import io\n",
    "\n",
    "def transcribe_audio(file_path):\n",
    "    client = speech.SpeechClient()\n",
    "\n",
    "    with io.open(file_path, \"rb\") as audio_file:\n",
    "        content = audio_file.read()\n",
    "    \n",
    "    audio = speech.RecognitionAudio(content=content)\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=16000,\n",
    "        language_code=\"en-US\",\n",
    "    )\n",
    "\n",
    "    response = client.recognize(config=config, audio=audio)\n",
    "\n",
    "    for result in response.results:\n",
    "        print(\"Transcript: {}\".format(result.alternatives[0].transcript))\n",
    "\n",
    "# Example usage\n",
    "transcribe_audio(\"processes\\\\speech.wav\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
