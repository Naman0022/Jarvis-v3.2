{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import numpy as np\n",
    "import wave\n",
    "import spacy\n",
    "import math\n",
    "import datetime\n",
    "import time\n",
    "import playsound\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "lemmatizer = nlp.get_pipe(\"lemmatizer\")\n",
    "first=True\n",
    "quit = False\n",
    "\n",
    "# Parameters\n",
    "sample_rate = 44100  # Sample rate in Hz\n",
    "channels = 1  # Number of audio channels (1 for mono, 2 for stereo)\n",
    "silence_threshold_multiplier = 1.5  # Multiplier for silence threshold\n",
    "silence_duration = 2  # Duration of silence to stop recording (in seconds)\n",
    "calibration_duration = 2  # Duration for noise calibration (in seconds)\n",
    "chunk_size = 1024  # Number of frames per buffer\n",
    "file_name = 'processes\\\\speech.wav'  # Output file name\n",
    "threshold = 400\n",
    "txt,token,entity,propnoun,noun,verb,adjective,number,tense,answer_casual = None,None,None,None,None,None,None,None,None,None\n",
    "with open(\"processes\\\\log.txt\", 'r') as file:\n",
    "      text = file.read()\n",
    "messages = [{\"role\": \"user\", \"content\": text}]\n",
    "whisper_api_calls = 0\n",
    "input_device = 1\n",
    "speak_thread = None\n",
    "\n",
    "\n",
    "from huggingface_hub import InferenceClient\n",
    "client = InferenceClient(\n",
    "        \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "        token=\"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\",\n",
    "    )\n",
    "\n",
    "def calibrate_noise(stream, sample_rate, channels, duration, chunk_size):\n",
    "    print(\"Getting Ready...\")\n",
    "    noise = []\n",
    "    for i in range(0,2):\n",
    "        noise_data = []\n",
    "        num_chunks = int(sample_rate * duration / chunk_size)\n",
    "        for _ in range(num_chunks):\n",
    "            data = np.frombuffer(stream.read(chunk_size), dtype=np.int16)\n",
    "            noise_data.append(data)\n",
    "        noise_data = np.concatenate(noise_data)\n",
    "        noise_level = np.max(np.abs(noise_data))\n",
    "        # print(f\"Calibration done. Noise level: {noise_level}\")\n",
    "        noise.append(noise_level)\n",
    "    return noise\n",
    "\n",
    "def is_silent(data, threshold):\n",
    "    # Check if the maximum amplitude in the data is below the threshold\n",
    "    return np.max(np.abs(data)) < threshold\n",
    "\n",
    "def bot():\n",
    "    global first,threshold,whisper_api_calls,input_device\n",
    "    \n",
    "    while True:\n",
    "        p = pyaudio.PyAudio()\n",
    "        if(first):\n",
    "            first = False\n",
    "            input_device = 1\n",
    "            for i in range(0, p.get_host_api_info_by_index(0).get('deviceCount')):\n",
    "                if (p.get_device_info_by_host_api_device_index(0, i).get('maxInputChannels')) > 0 and \"Headset\" in p.get_device_info_by_host_api_device_index(0, i).get('name'):\n",
    "                    input_device = i\n",
    "            print(\"Using:\",p.get_device_info_by_host_api_device_index(0, input_device).get('name'))\n",
    "            # Calibrate noise level\n",
    "            noise_level = calibrate_noise(p.open(format=pyaudio.paInt16, channels=channels, rate=sample_rate, input=True, frames_per_buffer=chunk_size), sample_rate, channels, calibration_duration, chunk_size)\n",
    "            threshold = (sum(noise_level) / len(noise_level) if len(noise_level) > 0 else MemoryError(\"noise array is of 0 length\")) * silence_threshold_multiplier  # Set threshold to a multiplier of the noise level\n",
    "            threshold+=100\n",
    "            if threshold > 1500:\n",
    "                print(\"It sure is noisy out there. Please speak loud and Clear.\")\n",
    "            elif threshold > 3000:\n",
    "                print(\"Sorry too much noise out there. I may not work properly.\")\n",
    "                first = True\n",
    "            print(f'Noise level: {math.floor(threshold/60)}%')\n",
    "          \n",
    "        # Open audio stream\n",
    "        start = time.process_time()\n",
    "        stream = p.open(format=pyaudio.paInt16, channels=channels, rate=sample_rate, input=True, frames_per_buffer=chunk_size,input_device_index=input_device)\n",
    "        playsound.playsound(\"audio_effects\\\\start.wav\")\n",
    "\n",
    "        recording = []\n",
    "        silence_start = None\n",
    "        silence_duration_frames = int(silence_duration * sample_rate / chunk_size)\n",
    "\n",
    "        try:\n",
    "            while True:\n",
    "                data = np.frombuffer(stream.read(chunk_size), dtype=np.int16)\n",
    "                recording.append(data)\n",
    "                if is_silent(data, threshold):\n",
    "                    if silence_start is None:\n",
    "                        silence_start = len(recording)\n",
    "                    elif len(recording) - silence_start >= silence_duration_frames:\n",
    "                        break\n",
    "                else:\n",
    "                    silence_start = None\n",
    "        except KeyboardInterrupt:\n",
    "            pass\n",
    "\n",
    "        playsound.playsound(\"audio_effects\\\\stop.wav\")\n",
    "        # Stop and close the stream\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "        p.terminate()\n",
    "\n",
    "\n",
    "\n",
    "        # Convert list to numpy array\n",
    "        recording = np.concatenate(recording)\n",
    "\n",
    "        # Save the recording to a WAV file\n",
    "        with wave.open(file_name, 'w') as wf:\n",
    "            wf.setnchannels(channels)\n",
    "            wf.setsampwidth(p.get_sample_size(pyaudio.paInt16))\n",
    "            wf.setframerate(sample_rate)\n",
    "            wf.writeframes(recording.tobytes())\n",
    "        \n",
    "        whisper_api_calls = 1\n",
    "        getText(file_name)\n",
    "        print(\"-\",round(time.process_time() - start,2))\n",
    "        if (quit):\n",
    "            break\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ytmusicapi import YTMusic\n",
    "\n",
    "# yt = YTMusic('oauth.json')\n",
    "# # playlistId = yt.create_playlist('test', 'test description')\n",
    "# search_results = yt.search('Oasis Wonderwall')\n",
    "# yt.add_playlist_items(playlistId, [search_results[0]['videoId']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "lemmatizer = nlp.get_pipe(\"lemmatizer\")\n",
    "\n",
    "import pyttsx3,playsound,time\n",
    "def express(_express):\n",
    "    playsound.playsound(\"audio_effects/\"+str(_express)+\".wav\")\n",
    "    time.sleep(0.1)\n",
    "\n",
    "# def say(txt):\n",
    "#     global CHUNK_SIZE,url,headers,data\n",
    "#     data[\"text\"] = txt\n",
    "#     response = requests.post(url, json=data, headers=headers)\n",
    "#     with open('processes\\\\out.wav', 'wb') as f:\n",
    "#         for chunk in response.iter_content(chunk_size=CHUNK_SIZE):\n",
    "#             if chunk:\n",
    "#                 f.write(chunk)\n",
    "engine = pyttsx3.init()\n",
    "voices = engine.getProperty('voices')\n",
    "engine.setProperty('voice',voices[1].id)\n",
    "engine.setProperty('rate', 180)\n",
    "def print_speak(txt):\n",
    "    parts = txt.split(\"*\")\n",
    "    expression = [\"sigh\",\"sighs\",\"wink\",\"winks\"] #,\"facepalm\",\"eyeroll\",\"eyerolls\"\n",
    "    print(parts)\n",
    "    print(\"BOT >> \",end=\"\")\n",
    "    for part in parts:\n",
    "        if part == \"\":\n",
    "            continue\n",
    "        elif part in [\".\",\"?\",\"!\"]:\n",
    "            print(part,end=\"\")\n",
    "        elif nlp(part.lower())[0].lemma_ in expression:\n",
    "            print(\"*\"+nlp(part)[0].lemma_+\"* \",end=\"\")\n",
    "            express(nlp(part)[0].lemma_)\n",
    "        else:\n",
    "            print(part,end=\"\")\n",
    "            engine.say(part)\n",
    "            engine.runAndWait()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'Wink', \" Oh, okay then. I guess I wasn't good enough for you, Sir. \", 'Sigh', ' Well, it was a pleasure not answering your questions. Have a great day... or not. ', 'Wink', '']\n",
      "BOT >> *wink*  Oh, okay then. I guess I wasn't good enough for you, Sir. *Sigh*  Well, it was a pleasure not answering your questions. Have a great day... or not. *wink* \n"
     ]
    }
   ],
   "source": [
    "print_speak(\"*Wink* Oh, okay then. I guess I wasn't good enough for you, Sir. *Sigh* Well, it was a pleasure not answering your questions. Have a great day... or not. *Wink*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    futures = {executor.submit(condition): condition for condition in [speak,print]conditions}\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        result = future.result()\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speak(text):\n",
    "    parts = text.split(\"*\")\n",
    "    expression = [\"sigh\",\"sighs\",\"wink\",\"winks\"] #,\"facepalm\",\"eyeroll\",\"eyerolls\"\n",
    "    \n",
    "    for part in parts:\n",
    "        if part == \".\":\n",
    "            continue\n",
    "        if part.lower() in expression:\n",
    "            express(nlp(part).lemma_)\n",
    "        else:\n",
    "            engine.say(part)\n",
    "            engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, time\n",
    "from gtts import gTTS\n",
    "import threading\n",
    "\n",
    "\n",
    "def getText(path):\n",
    "    global whisper_api_calls\n",
    "\n",
    "    API_URL = \"https://api-inference.huggingface.co/models/openai/whisper-medium\"\n",
    "    headers = {\"Authorization\": \"Bearer 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\"}\n",
    "\n",
    "    def query(filename):\n",
    "        with open(filename, \"rb\") as f:\n",
    "            data = f.read()\n",
    "        payload = {\n",
    "            \"parameters\": {\n",
    "                \"language\": \"en\"  # Set the language to English\n",
    "            }\n",
    "        }\n",
    "        response = requests.post(API_URL, headers=headers, json=payload, data=data)\n",
    "        return response.json()\n",
    "\n",
    "    results = query(path)\n",
    "    # print(time.process_time() - start)\n",
    "    if (\"text\" not in results or (results[\"text\"] == \"...\" or results[\"text\"] == \"\")):\n",
    "        speak(\"please say that again...\")\n",
    "        return\n",
    "    if \"error\" in results:\n",
    "        if whisper_api_calls == 1:\n",
    "            print(\"r_Wisper..\")\n",
    "        elif whisper_api_calls < 4:\n",
    "            whisper_api_calls+=1\n",
    "            return getText(path)\n",
    "        else:\n",
    "            speak(\"please say that again...\")\n",
    "            return\n",
    "    with open(\"processes/log.txt\", \"a\") as file:\n",
    "            file.write((\"_\"*20))\n",
    "            file.write(\"\\n\"+str(datetime.datetime.now())+\"\\n\")\n",
    "            file.write(\"User >> \"+str(results[\"text\"])+\"\\n\")\n",
    "    return tokenize(results)\n",
    "\n",
    "def tokenize(results):\n",
    "    global txt,token,entity,propnoun,noun,verb,adjective,number,tense,answer_casual,engine\n",
    "    txt = results[\"text\"]\n",
    "    doc = nlp(txt.lower())\n",
    "\n",
    "    tense=[]\n",
    "\n",
    "    for token in doc:\n",
    "        if token.pos_ == \"VERB\":\n",
    "            if token.tag_ in [\"VBD\", \"VBN\"]:  # Past tense\n",
    "                tense = [1,0]\n",
    "            elif token.tag_ in [\"VBP\", \"VBZ\", \"VBG\"]:  # Present tense\n",
    "                tense = [0,1]\n",
    "        tense = [0,0]  \n",
    "\n",
    "\n",
    "    token = [token.lemma_ for token in doc if token.pos_ != 'PUNCT']\n",
    "\n",
    "    propnoun = [token.lemma_ for token in doc if token.pos_ == 'PROPN']\n",
    "\n",
    "    entity = [ent.text for ent in doc.ents]\n",
    "\n",
    "    noun = [token.lemma_ for token in doc if token.pos_ == 'NOUN']\n",
    "    verb = [token.lemma_ for token in doc if token.pos_ == 'VERB']\n",
    "    adjective = [token.lemma_ for token in doc if token.pos_ == 'ADJ' or token.pos_ == 'ADP']\n",
    "    number = [token.lemma_ for token in doc if token.pos_ == 'NUM']\n",
    "\n",
    "    if isCommand():\n",
    "        return\n",
    "    else:\n",
    "        speak(answer_casual)\n",
    "        with open(\"processes/log.txt\", \"a\") as file:\n",
    "            file.write(\"BOT >> \" + answer_casual+\"\\n\")\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures,re,threading\n",
    "from googlesearch import search\n",
    "\n",
    "\n",
    "def casual():\n",
    "    global messages,client,answer_casual,txt,speak_thread\n",
    "    messages.append({\"role\": \"user\", \"content\": str(txt)})\n",
    "    # mess = \"\"\n",
    "    # res=[]\n",
    "    # for message in client.chat_completion(\n",
    "    #     messages=messages,\n",
    "    #     max_tokens=500,\n",
    "    #     stream=True,\n",
    "    # ):\n",
    "    #     mess += message.choices[0].delta.content\n",
    "    #     if len(re.findall(\"\\.\\s\",mess))>0:\n",
    "    #         res = mess.split(\".\")\n",
    "    #         print(res[0])\n",
    "            \n",
    "    #         res.pop(0)\n",
    "    #         if res:\n",
    "    #             mess = res[0]\n",
    "\n",
    "    message = client.chat_completion(\n",
    "        messages=messages,\n",
    "        temperature=0.7,\n",
    "        max_tokens=6000,\n",
    "        stream=False,\n",
    "    )\n",
    "    answer_casual = message.choices[0].message.content\n",
    "\n",
    "def google_search(query, num_results=5):\n",
    "    try:\n",
    "        for i, result in enumerate(search(query, num_results=num_results, stop=num_results)):\n",
    "            print(f\"Result {i+1}: {result}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "def check_condition_1():\n",
    "\n",
    "    if True in [nlp(str(v)).similarity(nlp(\"find\"))>0.5 for v in verb+noun] or True in [nlp(str(v)).similarity(nlp(\"information\"))>0.5 for v in verb+noun] or \"instagram\" in token:\n",
    "        if 'linkden' in token or 'linden' in token:\n",
    "            print(\"case1\")\n",
    "            text = \"\".join([ent+\" \" for ent in entity if ent != \"linkden\" or ent != \"linden\"])\n",
    "            if text == \"\":\n",
    "                text = \"\".join([ent+\" \" for ent in propnoun if ent != \"information\"])\n",
    "            if text == \"\":\n",
    "                text = \"\".join([ent+\" \" for ent in noun if ent != \"information\"])\n",
    "            \n",
    "            return text\n",
    "        if \"instagram\" in token:\n",
    "            print(\"here\")\n",
    "            return google_search(\"\".join(token.remove(\"instagram\"))+\" site:instagram.com\")\n",
    "        if \"google\" in token:\n",
    "            return \"google\"\n",
    "\n",
    "def check_condition_2():\n",
    "    if \"volume\" in noun:\n",
    "        if number:\n",
    "            return f\"volume:{number[0]}\"\n",
    "        elif \"up\" in adjective:\n",
    "            return \"volume:10\"\n",
    "        elif \"down\" in adjective:\n",
    "            return \"volume:-10\"\n",
    "\n",
    "def check_condition_3():\n",
    "    if 'restart' in verb:\n",
    "        if number:\n",
    "            return f\"restart:{number[0]}\"\n",
    "        return \"restart:60\"\n",
    "    if 'shut' in verb and \"down\" in adjective:\n",
    "        if number:\n",
    "            return f\"shutdown:{number[0]}\"\n",
    "        return \"shutdown:60\"\n",
    "    if 'log' in verb and \"off\" in adjective:\n",
    "        return \"logoff\"\n",
    "\n",
    "def check_condition_4():\n",
    "    if True in [nlp(str(v)).similarity(nlp(\"generate\"))>0.5 for v in verb] and \"image\" in noun:\n",
    "        return \"generate:Image\"\n",
    "\n",
    "def check_condition_5():\n",
    "    if \"battery\" in noun:\n",
    "        return \"battery:status\"\n",
    "\n",
    "def check_condition_6():\n",
    "    global quit,txt\n",
    "    if \"quit\" in token and not noun+propnoun:\n",
    "        txt = \"I will leave now\"\n",
    "        casual()\n",
    "        say(answer_casual)\n",
    "        quit = True\n",
    "        return \"quit\"\n",
    "\n",
    "# def check_condition_7():\n",
    "#     # Your condition here\n",
    "#     if False:  # Example condition\n",
    "#         return \"Condition 7 is true\"\n",
    "\n",
    "# def check_condition_8():\n",
    "#     # Your condition here\n",
    "#     if False:  # Example condition\n",
    "#         return \"Condition 8 is true\"\n",
    "\n",
    "def isCommand():\n",
    "    conditions = [\n",
    "        check_condition_1,\n",
    "        check_condition_2,\n",
    "        check_condition_3,\n",
    "        check_condition_4,\n",
    "        check_condition_5,\n",
    "        check_condition_6,\n",
    "        casual,\n",
    "    ]\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        futures = {executor.submit(condition): condition for condition in conditions}\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            result = future.result()\n",
    "            if result:\n",
    "                print(result)\n",
    "                with open(\"processes/log.txt\", \"a\") as file:\n",
    "                    file.write(\"BOT >> \"+result+\"\\n\")\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "\n",
    "# CHUNK_SIZE = 1024\n",
    "# url = \"https://api.elevenlabs.io/v1/text-to-speech/iP95p4xoKVk53GoZ742B\"\n",
    "\n",
    "# headers = {\n",
    "#   \"Accept\": \"audio/mpeg\",\n",
    "#   \"Content-Type\": \"application/json\",\n",
    "#   \"xi-api-key\": \"sk_424610e65712905fabd9cc2874aa8c61fb996d3a24f40e99\"\n",
    "# }\n",
    "\n",
    "# data = {\n",
    "#   \"text\": \"*Wink* Oh, I'm doing great, thanks for asking! Just living the dream, one Netflix binge-fest at a time. And you, Sir? *Sigh*\",\n",
    "#   \"model_id\": \"eleven_monolingual_v1\",\n",
    "#   \"voice_settings\": {\n",
    "#     \"stability\": 0.5,\n",
    "#     \"similarity_boost\": 0.5\n",
    "#   }\n",
    "# }\n",
    "\n",
    "# def speak(txt):\n",
    "#     global CHUNK_SIZE,url,headers,data\n",
    "#     data[\"text\"] = txt\n",
    "#     response = requests.post(url, json=data, headers=headers)\n",
    "#     with open('output.mp3', 'wb') as f:\n",
    "#         for chunk in response.iter_content(chunk_size=CHUNK_SIZE):\n",
    "#             if chunk:\n",
    "#                 f.write(chunk)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rec... Done\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "run loop already started",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mbot\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[23], line 122\u001b[0m, in \u001b[0;36mbot\u001b[1;34m()\u001b[0m\n\u001b[0;32m    119\u001b[0m     wf\u001b[38;5;241m.\u001b[39mwriteframes(recording\u001b[38;5;241m.\u001b[39mtobytes())\n\u001b[0;32m    121\u001b[0m whisper_api_calls \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 122\u001b[0m \u001b[43mgetText\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;28mround\u001b[39m(time\u001b[38;5;241m.\u001b[39mprocess_time() \u001b[38;5;241m-\u001b[39m start,\u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (quit):\n",
      "Cell \u001b[1;32mIn[31], line 41\u001b[0m, in \u001b[0;36mgetText\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     39\u001b[0m         file\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow())\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     40\u001b[0m         file\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser >> \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[31], line 73\u001b[0m, in \u001b[0;36mtokenize\u001b[1;34m(results)\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 73\u001b[0m     \u001b[43mspeak\u001b[49m\u001b[43m(\u001b[49m\u001b[43manswer_casual\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocesses/log.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m     75\u001b[0m         file\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBOT >> \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m answer_casual\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[30], line 30\u001b[0m, in \u001b[0;36mspeak\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     29\u001b[0m     engine\u001b[38;5;241m.\u001b[39msay(part)\n\u001b[1;32m---> 30\u001b[0m     \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunAndWait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\MyStuff\\Code\\Python3.10\\bot\\.venv\\lib\\site-packages\\pyttsx3\\engine.py:177\u001b[0m, in \u001b[0;36mEngine.runAndWait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;124;03mRuns an event loop until all commands queued up until this method call\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;124;03mcomplete. Blocks during the event loop and returns when the queue is\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;124;03m@raise RuntimeError: When the loop is already running\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inLoop:\n\u001b[1;32m--> 177\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun loop already started\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inLoop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_driverLoop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: run loop already started"
     ]
    }
   ],
   "source": [
    "bot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello!', ' How are you?', \" I hope you're doing well.\"]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "mess = \"Hello! How are you? I hope you're doing well.\"\n",
    "\n",
    "# Regular expression to split by '.', '?', '!' and keep the delimiters\n",
    "split_pattern = re.compile(r'([.!?])')\n",
    "\n",
    "# Perform the split and include delimiters in the result\n",
    "split_result = split_pattern.split(mess)\n",
    "\n",
    "# Combine the delimiters with the preceding segments\n",
    "result = [split_result[i] + split_result[i + 1] for i in range(0, len(split_result) - 1, 2)]\n",
    "\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "info = p.get_host_api_info_by_index(0)\n",
    "numdevices = info.get('deviceCount')\n",
    "\n",
    "input_device = 1\n",
    "for i in range(0, p.get_host_api_info_by_index(0).get('deviceCount')):\n",
    "    if (p.get_device_info_by_host_api_device_index(0, i).get('maxInputChannels')) > 0 and \"Headset\" in p.get_device_info_by_host_api_device_index(0, i).get('name'):\n",
    "        input_device = i\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 'can', 'you', 'give', 'I', 'some', 'tip', 'for', 'do', 'data', 'structure', 'for', 'interview', 'preparation']\n",
      "['tip', 'data', 'structure', 'interview', 'preparation']\n",
      "['give', 'do']\n",
      "['for', 'for']\n",
      "[]\n",
      "[]\n",
      "[0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(token,noun,verb,adjective,entity_all,entity,tense,sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yadav']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verb+noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(True in [nlp(str(v)).similarity(nlp(\"find\"))>0.5 for v in verb+noun])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MyStuff\\Code\\Python3.10\\bot\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA failed with error CUDA driver version is insufficient for CUDA runtime version",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m model_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlarge-v3\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Run on GPU with FP16\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mWhisperModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfloat16\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# or run on GPU with INT8\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# model = WhisperModel(model_size, device=\"cuda\", compute_type=\"int8_float16\")\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# or run on CPU with INT8\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")\u001b[39;00m\n",
      "File \u001b[1;32md:\\MyStuff\\Code\\Python3.10\\bot\\.venv\\lib\\site-packages\\faster_whisper\\transcribe.py:145\u001b[0m, in \u001b[0;36mWhisperModel.__init__\u001b[1;34m(self, model_size_or_path, device, device_index, compute_type, cpu_threads, num_workers, download_root, local_files_only, files, **model_kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    139\u001b[0m     model_path \u001b[38;5;241m=\u001b[39m download_model(\n\u001b[0;32m    140\u001b[0m         model_size_or_path,\n\u001b[0;32m    141\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m    142\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mdownload_root,\n\u001b[0;32m    143\u001b[0m     )\n\u001b[1;32m--> 145\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m ctranslate2\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mWhisper(\n\u001b[0;32m    146\u001b[0m     model_path,\n\u001b[0;32m    147\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[0;32m    148\u001b[0m     device_index\u001b[38;5;241m=\u001b[39mdevice_index,\n\u001b[0;32m    149\u001b[0m     compute_type\u001b[38;5;241m=\u001b[39mcompute_type,\n\u001b[0;32m    150\u001b[0m     intra_threads\u001b[38;5;241m=\u001b[39mcpu_threads,\n\u001b[0;32m    151\u001b[0m     inter_threads\u001b[38;5;241m=\u001b[39mnum_workers,\n\u001b[0;32m    152\u001b[0m     files\u001b[38;5;241m=\u001b[39mfiles,\n\u001b[0;32m    153\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m    154\u001b[0m )\n\u001b[0;32m    156\u001b[0m tokenizer_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizer.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokenizer_bytes:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA failed with error CUDA driver version is insufficient for CUDA runtime version"
     ]
    }
   ],
   "source": [
    "from faster_whisper import WhisperModel\n",
    "\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "model_size = \"large-v3\"\n",
    "\n",
    "# Run on GPU with FP16\n",
    "model = WhisperModel(model_size, device=\"cuda\", compute_type=\"float16\")\n",
    "\n",
    "# or run on GPU with INT8\n",
    "# model = WhisperModel(model_size, device=\"cuda\", compute_type=\"int8_float16\")\n",
    "# or run on CPU with INT8\n",
    "# model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments, info = model.transcribe(\"processes\\\\speech.wav\", beam_size=5)\n",
    "\n",
    "print(\"Detected language '%s' with probability %f\" % (info.language, info.language_probability))\n",
    "\n",
    "for segment in segments:\n",
    "    print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
